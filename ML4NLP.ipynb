{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural language processing and modelling using Scikitlearn pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I am taking a data set including sms messages with labels indicating whether they are hams or spams, and try to come up with the model to predict spams, based on the content of the message. It contains the following parts:\n",
    "\n",
    "**Part 0: Loading data**\n",
    "\n",
    "**Part 1: Defining methods for preprocessing texts**\n",
    "\n",
    "**Part 2: Splitting data and applying processing methods on them**\n",
    "\n",
    "**Part 3: naive bayes method** \n",
    "\n",
    "**Part 4: k-fold hold out**\n",
    "\n",
    "**Part 5: Random Forest, Gradient Boosting and modelling by GridSearch**\n",
    "\n",
    "**Part 6: Pipeline**\n",
    "\n",
    "**Part 7: Feature union in pipeline**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t', header=None)#importing the tab delimited data set\n",
    "data.columns = ['label', 'sms'] #assigning apprpriate headers for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Defining methods for preprocessing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    '''this method does the following\n",
    "    1. normalizing all the words to lower size\n",
    "    2. removes punctuations\n",
    "    3. splits the words\n",
    "    4. removes the stopwords like am,is,have,you,...\n",
    "    5. lammetizes the words for example running-->run\n",
    "    '''\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())    # normalize case and remove punctuation\n",
    "    tokens = word_tokenize(text)    # tokenize text\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]    # lemmatize andremove stop words\n",
    "    return tokens\n",
    "def prep_data(text,method=CountVectorizer):\n",
    "    '''\n",
    "    this method counts either counts the words \n",
    "    in sentences (CountVectorizer) or wights them \n",
    "    based on their importance in the sentence \n",
    "    and entire data(TfidfVectorizer):\n",
    "    '''\n",
    "    count_vector = method(tokenizer=tokenize)\n",
    "    count_vector.fit(text)\n",
    "    doc_array = count_vector.transform(text).toarray()\n",
    "    frequency_matrix_count = pd.DataFrame(doc_array, columns=count_vector.get_feature_names())\n",
    "    return frequency_matrix_count,frequency_matrix_count.values,count_vector\n",
    "\n",
    "def vectorize(text,vectorizer):\n",
    "    '''\n",
    "    to use vectorizer extracted from prep_data in other data sets.\n",
    "    this is important because we need the same vectorizer built on \n",
    "    training data to be applied on test data. if we apply prep_data\n",
    "    twice, once on train data and once on test data, since the words \n",
    "    are different they wont be giving simmilar names in the headers\n",
    "    in the vectorized data frame. so model trained on train data cant be applied \n",
    "    on test data since they had seen different words\n",
    "    '''\n",
    "    doc_array=vectorizer.transform(text).toarray()\n",
    "    frequency_matrix_count = pd.DataFrame(doc_array, columns=vectorizer.get_feature_names())\n",
    "    return frequency_matrix_count,frequency_matrix_count.values\n",
    "    \n",
    "def display_results(y_test, y_pred):\n",
    "    '''\n",
    "    function to display confusion matrix\n",
    "    '''\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['seen', 'book'],\n",
       " ['need', 'homework'],\n",
       " ['consider', 'done'],\n",
       " ['book', 'amazing']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = ['Have you seen this book?',\n",
    "             'I need to do my homeworks ',\n",
    "            'consider it done!',\n",
    "            'this book is amazing']\n",
    "[tokenize (x) for x in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>book</th>\n",
       "      <th>consider</th>\n",
       "      <th>done</th>\n",
       "      <th>homework</th>\n",
       "      <th>need</th>\n",
       "      <th>seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazing  book  consider  done  homework  need  seen\n",
       "0        0     1         0     0         0     0     1\n",
       "1        0     0         0     0         1     1     0\n",
       "2        0     0         1     1         0     0     0\n",
       "3        1     1         0     0         0     0     0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df,vectorized,vectorizer=prep_data(documents)#uses countvectorizer\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>book</th>\n",
       "      <th>consider</th>\n",
       "      <th>done</th>\n",
       "      <th>homework</th>\n",
       "      <th>need</th>\n",
       "      <th>seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.61913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.785288</td>\n",
       "      <td>0.61913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    amazing     book  consider      done  homework      need      seen\n",
       "0  0.000000  0.61913  0.000000  0.000000  0.000000  0.000000  0.785288\n",
       "1  0.000000  0.00000  0.000000  0.000000  0.707107  0.707107  0.000000\n",
       "2  0.000000  0.00000  0.707107  0.707107  0.000000  0.000000  0.000000\n",
       "3  0.785288  0.61913  0.000000  0.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df,vectorized,vectorizer=prep_data(documents,method=TfidfVectorizer)#uses TfidfVectorizer\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Splitting data and applying processing methods on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in the original data set: 5568\n",
      "rows in the training set: 4176\n",
      "rows in the test set: 1392\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['sms'], data['label'], random_state=444)\n",
    "print('rows in the original data set: {}'.format(data.shape[0]))\n",
    "print('rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('rows in the test set: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### applying methods on training and testing data\n",
    "we are going to test most of the modellings in using two separate vectorizers that we designed, and we can then compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''1. Count vectorizer method'''\n",
    "df,training_data_count,vectorizer = prep_data(X_train)#vectorizing on training data and extracting vectorizer\n",
    "df,testing_data_count = vectorize(X_test,vectorizer)#applying extracted vectorizer on testing data\n",
    "'''2. Tfidf vectorizer method'''\n",
    "df,training_data_tfidf,vectorizer = prep_data(X_train,method=TfidfVectorizer)#vectorizing on training data and extracting vectorizer\n",
    "df,testing_data_tfidf = vectorize(X_test,vectorizer)#applying extracted vectorizer on testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: *naive bayes* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countvectorizer: Precision: 0.936 / Recall: 0.92 / Accuracy: 0.982\n",
      "TfidfVectorizer: Precision: 0.992 / Recall: 0.722 / Accuracy: 0.964\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data_count, y_train)\n",
    "predictions = naive_bayes.predict(testing_data_count)\n",
    "precision, recall, fscore, support = score(y_test, predictions, pos_label='spam', average='binary')\n",
    "print('countvectorizer: Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                         round(recall, 3),\n",
    "                                                         round((predictions==y_test).sum() / len(predictions),3)))\n",
    "\n",
    "naive_bayes.fit(training_data_tfidf, y_train)\n",
    "predictions = naive_bayes.predict(testing_data_tfidf)\n",
    "precision, recall, fscore, support = score(y_test, predictions, pos_label='spam', average='binary')\n",
    "print('TfidfVectorizer: Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                         round(recall, 3),\n",
    "                                                         round((predictions==y_test).sum() / len(predictions),3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: k-fold hold out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see bellow we use *n-split=5 * which means that training data will be splitted into 5 part and for part will be used as training and one as validation. Once finished the score will be reported. This will happen 5 times in total and we will end up with 5 scores, which give us good idea about how good the model performes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### countvectorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97248804,  0.97964072,  0.96646707,  0.97245509,  0.95688623])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, training_data_count, y_train, cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidftvectorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97607656,  0.98203593,  0.96766467,  0.96287425,  0.95928144])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, training_data_tfidf, y_train, cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Random Forest, Gradient Boosting and modelling by GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Random Forest; Count vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.974880</td>\n",
       "      <td>0.985629</td>\n",
       "      <td>0.973653</td>\n",
       "      <td>0.973653</td>\n",
       "      <td>0.970060</td>\n",
       "      <td>0.975575</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998802</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999102</td>\n",
       "      <td>0.999162</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>59.540338</td>\n",
       "      <td>1.570981</td>\n",
       "      <td>0.414299</td>\n",
       "      <td>0.048288</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.980861</td>\n",
       "      <td>0.983234</td>\n",
       "      <td>0.971257</td>\n",
       "      <td>0.974850</td>\n",
       "      <td>0.967665</td>\n",
       "      <td>0.975575</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.553275</td>\n",
       "      <td>14.606205</td>\n",
       "      <td>0.274529</td>\n",
       "      <td>0.063930</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.976077</td>\n",
       "      <td>0.984431</td>\n",
       "      <td>0.970060</td>\n",
       "      <td>0.973653</td>\n",
       "      <td>0.970060</td>\n",
       "      <td>0.974856</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.550068</td>\n",
       "      <td>1.285677</td>\n",
       "      <td>0.416906</td>\n",
       "      <td>0.048129</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.978469</td>\n",
       "      <td>0.980838</td>\n",
       "      <td>0.965269</td>\n",
       "      <td>0.973653</td>\n",
       "      <td>0.973653</td>\n",
       "      <td>0.974377</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>4</td>\n",
       "      <td>0.994012</td>\n",
       "      <td>0.994014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995810</td>\n",
       "      <td>0.994672</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>4.166853</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>0.080414</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.976077</td>\n",
       "      <td>0.982036</td>\n",
       "      <td>0.972455</td>\n",
       "      <td>0.973653</td>\n",
       "      <td>0.967665</td>\n",
       "      <td>0.974377</td>\n",
       "      <td>0.004707</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995210</td>\n",
       "      <td>0.994612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996708</td>\n",
       "      <td>0.995690</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>90.971913</td>\n",
       "      <td>1.352475</td>\n",
       "      <td>0.601395</td>\n",
       "      <td>0.047223</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "7            0.974880           0.985629           0.973653   \n",
       "11           0.980861           0.983234           0.971257   \n",
       "10           0.976077           0.984431           0.970060   \n",
       "3            0.978469           0.980838           0.965269   \n",
       "5            0.976077           0.982036           0.972455   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "7            0.973653           0.970060         0.975575        0.005279   \n",
       "11           0.974850           0.967665         0.975575        0.005802   \n",
       "10           0.973653           0.970060         0.974856        0.005303   \n",
       "3            0.973653           0.973653         0.974377        0.005338   \n",
       "5            0.973653           0.967665         0.974377        0.004707   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  ...  \\\n",
       "7                 1            0.998802            0.999102  ...   \n",
       "11                1            1.000000            1.000000  ...   \n",
       "10                3            1.000000            1.000000  ...   \n",
       "3                 4            0.994012            0.994014  ...   \n",
       "5                 4            0.995210            0.994612  ...   \n",
       "\n",
       "    split4_train_score  mean_train_score  std_train_score  mean_fit_time  \\\n",
       "7             0.999102          0.999162         0.000224      59.540338   \n",
       "11            1.000000          1.000000         0.000000      80.553275   \n",
       "10            1.000000          1.000000         0.000000      61.550068   \n",
       "3             0.995810          0.994672         0.000935       4.166853   \n",
       "5             0.996708          0.995690         0.000724      90.971913   \n",
       "\n",
       "    std_fit_time  mean_score_time  std_score_time  param_max_depth  \\\n",
       "7       1.570981         0.414299        0.048288               90   \n",
       "11     14.606205         0.274529        0.063930             None   \n",
       "10      1.285677         0.416906        0.048129             None   \n",
       "3       0.064391         0.080414        0.006322               60   \n",
       "5       1.352475         0.601395        0.047223               60   \n",
       "\n",
       "    param_n_estimators                                    params  \n",
       "7                  150    {'max_depth': 90, 'n_estimators': 150}  \n",
       "11                 300  {'max_depth': None, 'n_estimators': 300}  \n",
       "10                 150  {'max_depth': None, 'n_estimators': 150}  \n",
       "3                   10     {'max_depth': 60, 'n_estimators': 10}  \n",
       "5                  300    {'max_depth': 60, 'n_estimators': 300}  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "         'max_depth': [30, 60, 90, None]}\n",
    "clf = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "clf_fit = clf.fit(training_data_count, y_train)\n",
    "pd.DataFrame(clf_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5] #metrics for all the nodes in grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=90, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=150, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(clf_fit.best_estimator_) #best estimator parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.847 / Accuracy: 0.981\n"
     ]
    }
   ],
   "source": [
    "predictions = clf_fit.best_estimator_.predict(testing_data_count)\n",
    "precision, recall, fscore, support = score(y_test, predictions, pos_label='spam', average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                         round(recall, 3),\n",
    "                                                         round((predictions==y_test).sum() / len(predictions),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Random Forest; Tfidf vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=90, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=300, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "Precision: 1.0 / Recall: 0.835 / Accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "''' Random Forest; tfidf'''\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "         'max_depth': [30, 60, 90, None]}\n",
    "clf = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "clf_fit = clf.fit(training_data_tfidf, y_train)\n",
    "pd.DataFrame(clf_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]\n",
    "\n",
    "print(clf_fit.best_estimator_)\n",
    "predictions = clf_fit.best_estimator_.predict(testing_data_tfidf)\n",
    "precision, recall, fscore, support = score(y_test, predictions, pos_label='spam', average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                         round(recall, 3),\n",
    "                                                         round((predictions==y_test).sum() / len(predictions),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Gradient Boosting; Count vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=7,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=150, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "Precision: 0.944 / Recall: 0.858 / Accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "''' Gradient Boosting; Count'''\n",
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [7, 11, 15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "clf = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "clf_fit = clf.fit(training_data_count, y_train)\n",
    "pd.DataFrame(clf_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]\n",
    "\n",
    "print(clf_fit.best_estimator_)\n",
    "predictions = clf_fit.best_estimator_.predict(testing_data_count)\n",
    "precision, recall, fscore, support = score(y_test, predictions, pos_label='spam', average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                         round(recall, 3),\n",
    "                                                         round((predictions==y_test).sum() / len(predictions),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Gradient Boosting; Tfidf vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=7,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=150, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n",
      "Precision: 0.948 / Recall: 0.83 / Accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "''' Gradient Boosting; tfidf'''\n",
    "gb = GradientBoostingClassifier()\n",
    "param = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [7, 11, 15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "clf = GridSearchCV(gb, param, cv=5, n_jobs=-1)\n",
    "clf_fit = clf.fit(training_data_tfidf, y_train)\n",
    "pd.DataFrame(clf_fit.cv_results_).sort_values('mean_test_score', ascending=False)[0:5]\n",
    "\n",
    "print(clf_fit.best_estimator_)\n",
    "predictions = clf_fit.best_estimator_.predict(testing_data_tfidf)\n",
    "precision, recall, fscore, support = score(y_test, predictions, pos_label='spam', average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                         round(recall, 3),\n",
    "                                                         round((predictions==y_test).sum() / len(predictions),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: PipeLine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a simple pipeline which applys count vectorizing followed by tfidf vectorizing on its output and then classifying using *Random Forest*. The first two consecutive lines in the pipeline has same results as *prep_data(X_train,method=TfidfVectorizer)* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_pipeline(): \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['ham' 'spam']\n",
      "Confusion Matrix:\n",
      " [[1216    0]\n",
      " [  37  139]]\n",
      "Accuracy: 0.97341954023\n"
     ]
    }
   ],
   "source": [
    "model = model_pipeline()\n",
    "model.fit(X_train, y_train);\n",
    "y_pred = model.predict(X_test)\n",
    "display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0 / Recall: 0.79 / Accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "precision, recall, fscore, support = score(y_test, predictions, pos_label='spam', average='binary')\n",
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                         round(recall, 3),\n",
    "                                                         round((predictions==y_test).sum() / len(predictions),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Feature union\n",
    "using this functionality we can do processes parallel to each other. As an example we want to bring the length of the texts into our calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' we need to wrap the appropriate method in a classed baed off BaseEstimator and TransformerMixin as bellow'''\n",
    "class TextLengthExtractor(BaseEstimator, TransformerMixin):\n",
    "    def text_length(self, text):\n",
    "        return len(text) - text.count(\" \")\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.text_length)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_pipeline2():\n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "\n",
    "            ('text_length', TextLengthExtractor())\n",
    "        ])),\n",
    "\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['ham' 'spam']\n",
      "Confusion Matrix:\n",
      " [[1216    0]\n",
      " [  38  138]]\n",
      "Accuracy: 0.972701149425\n"
     ]
    }
   ],
   "source": [
    "model = model_pipeline2()\n",
    "model.fit(X_train, y_train);\n",
    "y_pred = model.predict(X_test)\n",
    "display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.992 / Recall: 0.722 / Accuracy: 0.964\n"
     ]
    }
   ],
   "source": [
    "print('Precision: {} / Recall: {} / Accuracy: {}'.format(round(precision, 3),\n",
    "                                                         round(recall, 3),\n",
    "                                                         round((predictions==y_test).sum() / len(predictions),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can simply add Grid Search to our pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = model_pipeline2()\n",
    "param = {'n_estimators': [10, 150, 300],\n",
    "         'max_depth': [30, 60, 90, None]}\n",
    "model = GridSearchCV(pipeline, param, cv=5, n_jobs=-1)\n",
    "model.fit(X_train, y_train);\n",
    "y_pred = model.predict(X_test)\n",
    "display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
