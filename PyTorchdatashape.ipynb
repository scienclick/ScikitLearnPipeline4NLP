{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorchdatashape.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKyTb/4Q8loZbpSbxPYrdJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scienclick/ScikitLearnPipeline4NLP/blob/master/PyTorchdatashape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-On9I6wtw7JS",
        "outputId": "adfa8c24-2900-4960-9454-3972b85d95ea"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from torchtext.legacy import data\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzUDEfUGyC_i"
      },
      "source": [
        "def tokenize(text):\n",
        "    '''this method does the following\n",
        "    1. normalizing all the words to lower size\n",
        "    2. removes punctuations\n",
        "    3. splits the words\n",
        "    4. removes the stopwords like am,is,have,you,...\n",
        "    5. lammetizes the words for example running-->run\n",
        "    '''\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())    # normalize case and remove punctuation\n",
        "    tokens = word_tokenize(text)    # tokenize text\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]    # lemmatize andremove stop words\n",
        "    return tokens"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUPympRp9zh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "340e15cc-1c1c-41a6-cbca-46d6f5b9439a"
      },
      "source": [
        "text=[\"tree is beautiful definietly 100%\",\"seal likes fish too\",\"nature is see and tree \", \"Engineering is borring\",\"Programming is more fun\",\"life is such like 0 chanse\"]\n",
        "label=[0,0,0,1,1,2]\n",
        "ddf=pd.DataFrame({\"label\":label,\"text\":text})\n",
        "ddf"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>tree is beautiful definietly 100%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>seal likes fish too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>nature is see and tree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Engineering is borring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Programming is more fun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>life is such like 0 chanse</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                               text\n",
              "0      0  tree is beautiful definietly 100%\n",
              "1      0                seal likes fish too\n",
              "2      0            nature is see and tree \n",
              "3      1             Engineering is borring\n",
              "4      1            Programming is more fun\n",
              "5      2         life is such like 0 chanse"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPHB8N97yB5i"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hTYlmeBw3or"
      },
      "source": [
        "ddf.to_csv('thedata-explore.csv', index=False)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_iyeqOlxrLe"
      },
      "source": [
        "# TEXT = data.Field(sequential=True, batch_first=True, lower=True, pad_first=True, tokenize=tokenize)\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True, pad_first=True,)\n",
        "\n",
        "LABEL = data.Field(sequential=False, use_vocab=False, is_target=True)\n",
        "\n",
        "dataset = data.TabularDataset(path='thedata-explore.csv', format='csv', skip_header=True,\n",
        "                              fields=[('label', LABEL), ('text', TEXT)]\n",
        "                              )"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oZ0YjAzx4OL",
        "outputId": "ac0b57a1-02fd-4872-c009-9da0d95e256b"
      },
      "source": [
        "train_dataset, test_dataset = dataset.split(split_ratio=.75)  # default is 0.7\n",
        "len(train_dataset.examples)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z173lskOyhZE",
        "outputId": "0930d5d9-5398-47bf-a4cc-116974bf537c"
      },
      "source": [
        "ex = dataset.examples[3]\n",
        "print(ex.text)\n",
        "print(ex.label)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['engineering', 'is', 'borring']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxXqZehOyjsG"
      },
      "source": [
        "MAX_VOCAB_SIZE = 20\n",
        "\n",
        "TEXT.build_vocab(train_dataset,\n",
        "                 max_size=MAX_VOCAB_SIZE,\n",
        "                 # vectors=\"glove.6B.100d.txt\",\n",
        "                 # unk_init=torch.Tensor.normal_,\n",
        "                 min_freq=1,\n",
        "                 )\n",
        "LABEL.build_vocab(train_dataset)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqEFNO76y4Zh",
        "outputId": "8031bd58-16a3-4dc8-8ad5-867635879b6b"
      },
      "source": [
        "for i in range(len(TEXT.vocab)):\n",
        "    print(TEXT.vocab.itos[i])\n",
        "print(\"---------------------------\")\n",
        "for i in range(len(LABEL.vocab)):\n",
        "    print(LABEL.vocab.itos[i])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<unk>\n",
            "<pad>\n",
            "is\n",
            "0\n",
            "and\n",
            "borring\n",
            "chanse\n",
            "engineering\n",
            "fish\n",
            "life\n",
            "like\n",
            "likes\n",
            "nature\n",
            "seal\n",
            "see\n",
            "such\n",
            "too\n",
            "tree\n",
            "---------------------------\n",
            "<unk>\n",
            "0\n",
            "1\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAcCQewqzCgS"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator,  test_iterator = data.BucketIterator.splits(\n",
        "    (train_dataset,  test_dataset),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    sort_within_batch=False,\n",
        "    device=device)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG5q843YzXtP",
        "outputId": "d0bb1a45-e0ef-446a-b21b-66b6a82e6922"
      },
      "source": [
        "for batch in train_iterator:\n",
        "    # print(\"imput:\", inputs.shape, \"shape:\", targets.shape)\n",
        "    print(\"imput:\", batch.text, \"shape:\", batch.label)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imput: tensor([[ 1,  1, 13, 11,  8, 16],\n",
            "        [ 1, 12,  2, 14,  4, 17],\n",
            "        [ 1,  1,  1,  7,  2,  5],\n",
            "        [ 9,  2, 15, 10,  3,  6]]) shape: tensor([0, 0, 1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XiNg_a2zd2s",
        "outputId": "2cd4e031-0b58-4049-a4ba-79173c280707"
      },
      "source": [
        "for i in batch.text:\n",
        "    print(\"imput:\", [TEXT.vocab.itos[j] for j in i])"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imput: ['<pad>', '<pad>', 'seal', 'likes', 'fish', 'too']\n",
            "imput: ['<pad>', 'nature', 'is', 'see', 'and', 'tree']\n",
            "imput: ['<pad>', '<pad>', '<pad>', 'engineering', 'is', 'borring']\n",
            "imput: ['life', 'is', 'such', 'like', '0', 'chanse']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_SiI344zl8t",
        "outputId": "3ef8cce1-4216-4ef3-8416-cc29f1faf089"
      },
      "source": [
        "for batch in train_iterator:\n",
        "    print(\"imput:\", batch.text, \"shape:\", batch.label)\n",
        "    print(\"----------------------------------\")\n",
        "    for i in batch.text:\n",
        "        print(\"imput:\", [TEXT.vocab.itos[j] for j in i])\n",
        "\n",
        "    em=nn.Embedding(len(TEXT.vocab), 3)(batch.text.cpu())\n",
        "    print(\"*1---------------------------------\")\n",
        "    print(em)\n",
        "    print(\"---------------------------------\")\n",
        "    print(em.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imput: tensor([[ 1,  1,  1,  7,  2,  5],\n",
            "        [ 9,  2, 15, 10,  3,  6],\n",
            "        [ 1,  1, 13, 11,  8, 16],\n",
            "        [ 1, 12,  2, 14,  4, 17]]) shape: tensor([1, 2, 0, 0])\n",
            "----------------------------------\n",
            "imput: ['<pad>', '<pad>', '<pad>', 'engineering', 'is', 'borring']\n",
            "imput: ['life', 'is', 'such', 'like', '0', 'chanse']\n",
            "imput: ['<pad>', '<pad>', 'seal', 'likes', 'fish', 'too']\n",
            "imput: ['<pad>', 'nature', 'is', 'see', 'and', 'tree']\n",
            "*1---------------------------------\n",
            "tensor([[[ 0.3384,  0.5570, -1.1350],\n",
            "         [ 0.3384,  0.5570, -1.1350],\n",
            "         [ 0.3384,  0.5570, -1.1350],\n",
            "         [ 0.6288, -0.1714, -0.2968],\n",
            "         [-0.2097, -0.6370, -0.6590],\n",
            "         [ 1.8518, -1.2153,  0.1500]],\n",
            "\n",
            "        [[-0.7118, -1.1152, -0.3627],\n",
            "         [-0.2097, -0.6370, -0.6590],\n",
            "         [ 0.1636, -0.0309,  1.2614],\n",
            "         [ 0.1731,  1.7366, -1.1559],\n",
            "         [-0.4311, -0.3124, -1.4238],\n",
            "         [-0.2652,  1.5784,  0.4129]],\n",
            "\n",
            "        [[ 0.3384,  0.5570, -1.1350],\n",
            "         [ 0.3384,  0.5570, -1.1350],\n",
            "         [ 0.4038, -0.5693,  0.7636],\n",
            "         [-0.8501, -0.9525, -1.5877],\n",
            "         [ 0.4633, -0.4165,  0.0359],\n",
            "         [-1.3259, -0.9662,  0.6384]],\n",
            "\n",
            "        [[ 0.3384,  0.5570, -1.1350],\n",
            "         [ 0.9384,  1.1096, -2.0386],\n",
            "         [-0.2097, -0.6370, -0.6590],\n",
            "         [ 0.9146,  0.3312, -2.4937],\n",
            "         [ 0.3877,  0.7750,  0.9577],\n",
            "         [-0.1406,  0.6036,  0.2059]]], grad_fn=<EmbeddingBackward>)\n",
            "---------------------------------\n",
            "torch.Size([4, 6, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0tglpQ7z36F",
        "outputId": "f1ad5f9f-b1dd-4dbf-b94e-f58de58ff734"
      },
      "source": [
        "for batch in train_iterator:\n",
        "    print(\"imput:\", batch.text, \"shape:\", batch.label)\n",
        "    print(\"----------------------------------\")\n",
        "    for i in batch.text:\n",
        "        print(\"imput:\", [TEXT.vocab.itos[j] for j in i])\n",
        "\n",
        "    em=nn.Embedding(len(TEXT.vocab), 3)(batch.text.cpu())\n",
        "    em=em.permute(0, 2, 1)\n",
        "    print(\"*2---------------------------------\")\n",
        "    print(em)\n",
        "    print(\"---------------------------------\")\n",
        "    print(em.shape)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imput: tensor([[ 1,  1, 13, 11,  8, 16],\n",
            "        [ 9,  2, 15, 10,  3,  6],\n",
            "        [ 1, 12,  2, 14,  4, 17],\n",
            "        [ 1,  1,  1,  7,  2,  5]]) shape: tensor([0, 2, 0, 1])\n",
            "----------------------------------\n",
            "imput: ['<pad>', '<pad>', 'seal', 'likes', 'fish', 'too']\n",
            "imput: ['life', 'is', 'such', 'like', '0', 'chanse']\n",
            "imput: ['<pad>', 'nature', 'is', 'see', 'and', 'tree']\n",
            "imput: ['<pad>', '<pad>', '<pad>', 'engineering', 'is', 'borring']\n",
            "*2---------------------------------\n",
            "tensor([[[-0.1761, -0.1761, -0.2384,  0.2754, -0.2645, -0.3102],\n",
            "         [ 0.9617,  0.9617, -0.2439,  1.1979, -2.1688, -1.1989],\n",
            "         [-1.3849, -1.3849, -0.4108, -0.1680,  0.1365, -0.4480]],\n",
            "\n",
            "        [[ 0.0313, -0.9375, -1.2891,  1.4668,  1.7250, -1.0237],\n",
            "         [ 0.8918,  0.6981,  0.3701, -0.1802,  0.3027, -0.3452],\n",
            "         [-0.7358, -0.5887,  0.9754, -0.1357, -0.6981,  1.1448]],\n",
            "\n",
            "        [[-0.1761,  1.3165, -0.9375,  0.1613, -1.9093,  2.2364],\n",
            "         [ 0.9617,  2.0524,  0.6981,  0.2597, -0.2617,  1.5429],\n",
            "         [-1.3849,  0.0876, -0.5887, -0.7643,  1.0869, -2.8971]],\n",
            "\n",
            "        [[-0.1761, -0.1761, -0.1761,  0.6620, -0.9375,  0.8668],\n",
            "         [ 0.9617,  0.9617,  0.9617,  0.0744,  0.6981,  0.6945],\n",
            "         [-1.3849, -1.3849, -1.3849,  0.3185, -0.5887, -0.0132]]],\n",
            "       grad_fn=<PermuteBackward>)\n",
            "---------------------------------\n",
            "torch.Size([4, 3, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohxz14uW1B-U",
        "outputId": "add4b0aa-2113-469e-bbda-ea05e6788ec9"
      },
      "source": [
        "for batch in train_iterator:\n",
        "    print(\"imput:\", batch.text, \"shape:\", batch.label)\n",
        "    print(\"----------------------------------\")\n",
        "    for i in batch.text:\n",
        "        print(\"imput:\", [TEXT.vocab.itos[j] for j in i])\n",
        "\n",
        "    em=nn.Embedding(len(TEXT.vocab), 3)(batch.text.cpu())\n",
        "\n",
        "    em=em.permute(0, 2, 1)\n",
        "\n",
        "    c=nn.Conv1d(in_channels=3, out_channels=32, kernel_size=2, padding=1)(em)\n",
        "    print(\"*3---------------------------------\")\n",
        "    print(c)\n",
        "    print(\"----------------------------------\")\n",
        "\n",
        "    print(c.shape)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imput: tensor([[ 1,  1,  1,  7,  2,  5],\n",
            "        [ 9,  2, 15, 10,  3,  6],\n",
            "        [ 1, 12,  2, 14,  4, 17],\n",
            "        [ 1,  1, 13, 11,  8, 16]]) shape: tensor([1, 2, 0, 0])\n",
            "----------------------------------\n",
            "imput: ['<pad>', '<pad>', '<pad>', 'engineering', 'is', 'borring']\n",
            "imput: ['life', 'is', 'such', 'like', '0', 'chanse']\n",
            "imput: ['<pad>', 'nature', 'is', 'see', 'and', 'tree']\n",
            "imput: ['<pad>', '<pad>', 'seal', 'likes', 'fish', 'too']\n",
            "*3---------------------------------\n",
            "tensor([[[-5.3554e-01, -6.2198e-01, -6.2198e-01, -2.5777e-01, -1.2642e-01,\n",
            "           2.7617e-01, -5.2339e-01],\n",
            "         [-7.7039e-01, -7.8869e-01, -7.8869e-01, -6.9216e-01, -1.3907e+00,\n",
            "           6.4337e-01,  1.6118e-03],\n",
            "         [ 8.5423e-01,  1.0953e+00,  1.0953e+00,  9.0420e-01,  1.1357e+00,\n",
            "          -2.1333e-01,  2.3084e-01],\n",
            "         [-3.6586e-01,  6.8581e-01,  6.8581e-01,  7.1870e-01, -9.0954e-01,\n",
            "           1.3028e+00, -7.6729e-01],\n",
            "         [-3.6967e-01, -5.9134e-01, -5.9134e-01, -7.0309e-01, -3.7847e-01,\n",
            "           4.0393e-01, -4.4415e-01],\n",
            "         [ 9.0274e-01,  2.6197e-01,  2.6197e-01, -2.0629e-01,  1.1464e+00,\n",
            "          -1.2449e+00,  6.3998e-01],\n",
            "         [ 1.9136e-01, -4.0113e-01, -4.0113e-01, -7.2336e-01, -1.4533e-01,\n",
            "          -1.8522e+00,  4.3099e-01],\n",
            "         [ 6.0497e-01,  1.4711e+00,  1.4711e+00,  7.7627e-01,  8.1272e-01,\n",
            "           4.4075e-01, -9.2891e-01],\n",
            "         [-9.4128e-03,  7.6328e-01,  7.6328e-01,  4.3233e-01, -1.0602e-01,\n",
            "           5.7121e-01, -1.1101e+00],\n",
            "         [-4.1372e-01,  1.1906e-01,  1.1906e-01,  7.2979e-03, -9.2409e-01,\n",
            "           5.2571e-01, -3.5071e-01],\n",
            "         [ 1.5412e+00,  7.7669e-01,  7.7669e-01, -2.5794e-01,  1.4960e+00,\n",
            "          -1.1408e+00,  8.2187e-01],\n",
            "         [-1.1214e+00, -1.6868e+00, -1.6868e+00, -1.0988e+00, -1.4440e+00,\n",
            "          -2.5336e-01,  3.5942e-01],\n",
            "         [-6.6083e-01,  1.4365e-01,  1.4365e-01,  5.8929e-01, -1.5524e-01,\n",
            "           1.0617e+00, -1.1062e+00],\n",
            "         [-6.4593e-01, -1.4231e-01, -1.4231e-01,  3.7163e-01, -7.5480e-02,\n",
            "           5.8860e-01, -6.6851e-01],\n",
            "         [ 3.8713e-01, -3.2822e-01, -3.2822e-01, -9.0629e-01, -1.2540e-01,\n",
            "          -9.5788e-01,  5.7222e-01],\n",
            "         [ 1.6285e-01,  1.1739e+00,  1.1739e+00,  1.2645e+00,  4.0117e-01,\n",
            "           3.1586e-01, -6.7952e-01],\n",
            "         [ 8.5413e-01,  9.9047e-01,  9.9047e-01,  9.4158e-02,  9.6204e-01,\n",
            "          -5.2567e-01, -3.4544e-01],\n",
            "         [-5.5287e-01,  3.3151e-01,  3.3151e-01,  9.7514e-01, -9.8535e-02,\n",
            "           1.3686e+00, -7.0636e-01],\n",
            "         [-7.4914e-01, -9.2369e-01, -9.2369e-01, -2.6304e-01, -4.8255e-01,\n",
            "           4.1494e-01,  8.5595e-02],\n",
            "         [ 2.0536e-02,  6.1811e-01,  6.1811e-01,  4.1918e-01, -1.7052e-01,\n",
            "           1.0600e+00, -2.1647e-01],\n",
            "         [ 2.5457e-01, -3.4568e-01, -3.4568e-01, -2.0954e-01,  7.1588e-01,\n",
            "          -7.4205e-01,  3.3968e-01],\n",
            "         [ 3.8213e-01, -1.3772e-02, -1.3772e-02, -3.9042e-01, -6.6959e-02,\n",
            "          -2.9320e-01,  6.3321e-01],\n",
            "         [-2.5280e-01, -9.2405e-01, -9.2405e-01, -1.2440e+00, -1.1708e+00,\n",
            "           2.9373e-03,  7.4481e-01],\n",
            "         [ 3.8321e-01, -4.4898e-01, -4.4898e-01, -7.4909e-01,  3.0345e-01,\n",
            "          -1.7510e+00,  5.8795e-01],\n",
            "         [ 6.4347e-02,  6.5314e-01,  6.5314e-01,  1.0560e+00,  3.9680e-01,\n",
            "          -3.3604e-01, -3.1073e-01],\n",
            "         [ 2.3611e-01, -1.4615e-01, -1.4615e-01,  1.3887e-01,  5.0108e-01,\n",
            "          -1.5044e+00,  3.0931e-01],\n",
            "         [ 8.5760e-01,  8.9105e-01,  8.9105e-01,  1.9943e-01,  1.1753e+00,\n",
            "          -1.1211e-02, -3.7051e-01],\n",
            "         [ 1.3665e-01,  5.6764e-01,  5.6764e-01,  9.6095e-01,  3.9818e-01,\n",
            "           6.1985e-01, -1.8220e-01],\n",
            "         [ 8.0019e-01,  2.0192e-01,  2.0192e-01, -1.4329e-01,  1.0486e+00,\n",
            "          -1.3299e+00,  4.1200e-01],\n",
            "         [ 3.3685e-01, -4.4368e-01, -4.4368e-01, -9.8131e-01, -8.0191e-03,\n",
            "          -6.9298e-01,  2.6221e-01],\n",
            "         [ 5.4173e-02,  9.9637e-01,  9.9637e-01,  1.2734e+00,  1.9696e-02,\n",
            "           9.2434e-01, -5.5921e-01],\n",
            "         [-2.2267e-02, -1.1571e+00, -1.1571e+00, -1.5278e+00,  1.2501e-02,\n",
            "          -1.4283e+00,  4.2885e-01]],\n",
            "\n",
            "        [[ 5.6770e-01, -6.6419e-01,  3.0986e-01,  2.2646e-01, -3.1208e-01,\n",
            "           5.7787e-02, -3.2037e-01],\n",
            "         [-4.7315e-01, -1.7132e+00,  2.5962e-01,  4.1211e-01, -7.4663e-01,\n",
            "          -4.6066e-01, -1.2957e-01],\n",
            "         [-3.5914e-01,  1.3409e+00,  3.8180e-02, -4.4548e-01,  6.4463e-01,\n",
            "           4.5425e-01,  4.5288e-01],\n",
            "         [ 1.2174e+00, -6.7039e-01,  1.0520e+00, -3.2374e-01, -1.6960e+00,\n",
            "          -8.2795e-02,  2.9877e-01],\n",
            "         [ 4.0431e-01, -1.6883e+00,  1.9219e-01,  8.6968e-02, -5.8257e-01,\n",
            "           2.1377e-01, -3.7388e-01],\n",
            "         [ 2.7673e-02,  1.4495e+00, -1.0341e+00, -1.0927e-01,  1.2712e+00,\n",
            "           2.8222e-01, -7.4274e-02],\n",
            "         [-1.1753e+00, -1.1817e-01, -1.6903e+00, -5.9370e-01,  5.2989e-01,\n",
            "          -6.3211e-01, -5.6597e-01],\n",
            "         [ 4.6533e-01,  9.3636e-01,  4.1305e-01, -1.2963e+00, -8.3293e-01,\n",
            "           5.3501e-01,  2.5144e-01],\n",
            "         [ 5.1035e-01, -1.0532e+00,  4.8825e-01, -1.0967e+00, -1.4354e+00,\n",
            "           2.6898e-01, -7.6599e-02],\n",
            "         [ 1.4014e+00,  7.2230e-01,  2.3742e-01,  4.5018e-02, -1.0521e+00,\n",
            "          -4.9820e-01,  5.9956e-02],\n",
            "         [ 1.6957e+00,  1.6967e+00, -1.0857e+00, -6.7766e-03,  1.2230e+00,\n",
            "           7.9161e-01,  4.0524e-02],\n",
            "         [-9.3415e-01, -1.2633e+00, -4.0061e-01,  8.6053e-01,  4.0914e-02,\n",
            "          -9.3896e-01, -4.6903e-01],\n",
            "         [-7.7176e-01, -7.5297e-01,  1.1026e+00, -5.3546e-01, -9.8863e-01,\n",
            "           5.9541e-02,  6.4076e-02],\n",
            "         [-1.4089e+00, -4.8883e-02,  6.9010e-01, -2.9636e-01, -3.3671e-01,\n",
            "          -1.8535e-01,  5.2086e-02],\n",
            "         [ 1.3795e+00,  3.2616e-01, -1.1078e+00,  2.9731e-01,  3.4241e-01,\n",
            "          -1.1530e-01, -3.5156e-01],\n",
            "         [-1.3403e+00,  2.5541e-01,  5.5130e-01, -1.2077e+00, -5.6523e-01,\n",
            "           6.1780e-02,  3.6740e-01],\n",
            "         [-6.4342e-01,  2.4240e-01, -4.9118e-01, -1.2787e+00, -3.5210e-02,\n",
            "           4.9185e-01, -4.2974e-02],\n",
            "         [ 2.2346e-01,  5.0267e-01,  1.4084e+00,  1.0586e-01, -6.8689e-01,\n",
            "           5.2253e-02,  4.2428e-01],\n",
            "         [-1.1447e-01,  2.8452e-02,  3.9543e-01,  8.7423e-01,  1.9207e-01,\n",
            "          -3.1950e-01, -4.6941e-02],\n",
            "         [ 5.9438e-01,  6.8473e-01,  8.0150e-01,  2.8547e-02, -6.0331e-01,\n",
            "           1.3034e-01,  4.5628e-01],\n",
            "         [-1.3542e+00, -5.8731e-01, -4.6435e-01, -2.4511e-02,  1.0122e+00,\n",
            "           2.6598e-01, -1.9643e-01],\n",
            "         [-1.4663e-01, -3.0772e-01, -4.3203e-01,  2.1092e-01,  3.9267e-01,\n",
            "           6.6800e-02,  4.7656e-02],\n",
            "         [-1.3906e-01, -1.5640e+00, -4.5281e-01,  7.5968e-01, -2.3938e-02,\n",
            "          -3.2454e-01, -1.9834e-01],\n",
            "         [-6.2480e-01,  1.8030e-01, -1.5557e+00, -2.2102e-01,  9.4456e-01,\n",
            "          -2.8458e-01, -5.0844e-01],\n",
            "         [ 2.7913e-01,  1.5521e+00,  4.3883e-02, -4.7733e-01, -4.2391e-02,\n",
            "          -2.4089e-01,  1.6516e-01],\n",
            "         [ 3.3521e-02,  8.8670e-01, -1.0390e+00, -1.6677e-01,  8.2309e-01,\n",
            "          -3.0277e-01, -3.1618e-01],\n",
            "         [ 1.1133e+00,  4.4055e-01,  1.3654e-02, -6.0211e-01, -1.0219e-02,\n",
            "           8.8717e-01,  3.0601e-02],\n",
            "         [ 1.7211e-01, -2.4490e-01,  8.1523e-01, -2.0365e-02, -9.6422e-02,\n",
            "           4.1808e-01,  3.6122e-01],\n",
            "         [ 5.4584e-01,  9.9603e-01, -1.0474e+00, -2.0125e-01,  9.9188e-01,\n",
            "           2.7927e-01, -2.3173e-01],\n",
            "         [ 1.1644e+00, -1.1189e+00, -8.2651e-01,  1.5288e-01,  1.2131e-01,\n",
            "           2.6470e-01, -4.9362e-01],\n",
            "         [ 1.0040e+00,  2.1395e-02,  1.0206e+00, -3.3344e-01, -8.9532e-01,\n",
            "           2.5011e-01,  4.4178e-01],\n",
            "         [ 7.2407e-02,  1.5465e-01, -1.4718e+00,  2.8279e-01,  8.0568e-01,\n",
            "          -3.0696e-01, -7.5320e-01]],\n",
            "\n",
            "        [[-5.3554e-01, -5.1544e-01, -1.1781e+00, -7.4866e-01, -4.1352e-01,\n",
            "           5.9434e-01,  2.5950e-01],\n",
            "         [-7.7039e-01,  7.9181e-01, -8.0555e-01,  3.7563e-01,  4.4425e-01,\n",
            "          -5.3498e-01, -6.3397e-01],\n",
            "         [ 8.5423e-01,  8.6365e-02,  1.2618e+00,  7.5684e-01,  1.2661e-01,\n",
            "          -1.5326e-01,  1.1214e-01],\n",
            "         [-3.6586e-01,  1.4383e+00, -5.1742e-01,  1.9210e-01,  1.3197e+00,\n",
            "           2.6217e-01, -1.3768e+00],\n",
            "         [-3.6967e-01, -2.3148e-02, -1.2174e+00, -4.4831e-02, -3.8711e-02,\n",
            "          -3.8588e-01, -8.3818e-02],\n",
            "         [ 9.0274e-01, -9.7569e-01,  1.0079e+00, -3.0655e-01, -7.4306e-01,\n",
            "          -5.4047e-02,  1.0809e+00],\n",
            "         [ 1.9136e-01, -1.1848e+00,  1.2306e+00, -6.7975e-01, -8.5375e-02,\n",
            "          -1.2230e+00, -6.0501e-01],\n",
            "         [ 6.0497e-01,  7.7749e-01, -1.0142e-01,  1.0406e+00, -2.8221e-01,\n",
            "          -5.4309e-01, -3.4367e-01],\n",
            "         [-9.4128e-03,  6.0571e-01, -4.3860e-01,  4.5403e-01,  7.1727e-01,\n",
            "          -8.1101e-01, -1.3994e+00],\n",
            "         [-4.1372e-01,  8.0684e-01, -7.6267e-01, -6.3938e-01, -3.7977e-02,\n",
            "           8.9800e-01, -8.2442e-02],\n",
            "         [ 1.5412e+00, -7.0126e-01,  1.0956e+00, -4.9935e-01, -3.3200e-01,\n",
            "           2.3879e-01,  1.5022e+00],\n",
            "         [-1.1214e+00, -4.3693e-01, -7.0381e-01, -8.0540e-01, -2.4660e-01,\n",
            "           6.7974e-02, -5.8580e-02],\n",
            "         [-6.6083e-01,  5.3242e-01, -1.0435e+00,  8.1481e-01, -1.6692e-01,\n",
            "          -2.3506e-01, -7.8128e-01],\n",
            "         [-6.4593e-01,  2.0266e-01, -7.3326e-01,  7.4061e-01, -7.4277e-01,\n",
            "          -1.3913e-01, -2.3073e-01],\n",
            "         [ 3.8713e-01, -5.9840e-01,  2.0591e-01, -1.2207e+00, -9.9198e-02,\n",
            "           2.4678e-01,  6.6746e-01],\n",
            "         [ 1.6285e-01,  6.1504e-01,  8.2865e-01,  1.2822e+00,  5.3233e-01,\n",
            "          -9.2226e-01, -1.4448e+00],\n",
            "         [ 8.5413e-01,  4.9753e-02,  6.1044e-01,  1.1550e+00, -3.1941e-01,\n",
            "          -1.5787e+00, -3.2977e-01],\n",
            "         [-5.5287e-01,  8.0399e-01, -9.0016e-01,  3.6668e-01, -1.1646e-01,\n",
            "           1.0688e+00, -5.8110e-02],\n",
            "         [-7.4914e-01, -1.7117e-01, -9.4227e-01, -5.0051e-01, -6.4558e-01,\n",
            "           1.0260e+00,  7.3815e-01],\n",
            "         [ 2.0536e-02,  1.3026e+00, -5.0087e-01,  8.1317e-01, -4.5504e-02,\n",
            "           3.8828e-01,  1.9139e-01],\n",
            "         [ 2.5457e-01, -9.9888e-01,  6.3196e-01,  2.6331e-01, -1.9044e-01,\n",
            "          -7.7323e-01,  1.4589e-01],\n",
            "         [ 3.8213e-01,  1.7967e-01,  6.1337e-01,  3.4654e-01,  3.9996e-01,\n",
            "          -5.6919e-01,  6.3813e-02],\n",
            "         [-2.5280e-01,  4.7743e-01, -2.3077e-01,  1.6450e-01,  4.8327e-01,\n",
            "          -6.9939e-01, -2.3144e-02],\n",
            "         [ 3.8321e-01, -1.4016e+00,  1.0258e+00, -8.4244e-01, -3.5605e-01,\n",
            "          -6.9300e-01,  1.6448e-01],\n",
            "         [ 6.4347e-02, -4.0736e-01,  7.3493e-01, -7.8277e-01,  1.0740e-01,\n",
            "           8.6668e-01, -3.9471e-01],\n",
            "         [ 2.3611e-01, -1.6118e+00,  1.1750e+00, -1.5796e+00,  4.5791e-03,\n",
            "           4.4607e-01, -3.5536e-02],\n",
            "         [ 8.5760e-01, -7.6167e-02, -6.6822e-02,  3.1275e-01, -2.4792e-01,\n",
            "          -2.1059e-01,  4.7466e-01],\n",
            "         [ 1.3665e-01,  2.5718e-01,  3.9431e-01,  3.0707e-01,  9.4152e-01,\n",
            "           3.0459e-01, -5.4795e-01],\n",
            "         [ 8.0019e-01, -1.2821e+00,  9.4977e-01, -9.0982e-01, -3.3287e-01,\n",
            "           1.0568e-01,  6.7664e-01],\n",
            "         [ 3.3685e-01, -7.0160e-01, -9.2959e-02, -8.7182e-01,  3.2384e-01,\n",
            "          -3.6978e-01,  1.9646e-01],\n",
            "         [ 5.4173e-02,  7.7836e-01,  2.5961e-01,  6.7258e-02,  1.3279e+00,\n",
            "           5.7151e-01, -1.0807e+00],\n",
            "         [-2.2267e-02, -1.4432e+00, -4.2987e-01, -1.2244e+00, -1.4328e+00,\n",
            "          -1.0304e-01,  1.2465e+00]],\n",
            "\n",
            "        [[-5.3554e-01, -6.2198e-01,  3.6578e-01,  1.1203e+00,  2.6030e-02,\n",
            "          -6.7119e-01, -5.1518e-01],\n",
            "         [-7.7039e-01, -7.8869e-01, -1.2809e+00, -6.7658e-01, -1.9612e-01,\n",
            "          -1.7554e-02,  1.9188e-01],\n",
            "         [ 8.5423e-01,  1.0953e+00,  8.9589e-01, -1.2895e-01,  1.0036e-01,\n",
            "           5.8410e-01,  4.3486e-01],\n",
            "         [-3.6586e-01,  6.8581e-01,  7.5218e-01, -1.3884e+00, -5.6585e-01,\n",
            "          -3.9238e-01,  3.9034e-01],\n",
            "         [-3.6967e-01, -5.9134e-01, -9.3287e-01,  6.3814e-01,  1.0402e-01,\n",
            "          -4.3256e-01, -2.2929e-01],\n",
            "         [ 9.0274e-01,  2.6197e-01, -3.4855e-01,  6.1338e-01,  4.9328e-01,\n",
            "           3.6111e-01, -2.4929e-01],\n",
            "         [ 1.9136e-01, -4.0113e-01, -1.0288e+00, -1.6989e+00, -2.5747e-01,\n",
            "          -4.9026e-02, -9.9355e-02],\n",
            "         [ 6.0497e-01,  1.4711e+00,  2.7360e-01, -1.1380e-01, -4.2478e-01,\n",
            "           8.7068e-02, -9.2636e-02],\n",
            "         [-9.4128e-03,  7.6328e-01,  2.4263e-01, -1.0266e+00, -5.8371e-01,\n",
            "          -4.8186e-01,  1.5611e-01],\n",
            "         [-4.1372e-01,  1.1906e-01, -4.3093e-02, -4.9961e-01, -3.7687e-01,\n",
            "          -3.6678e-01, -4.3492e-01],\n",
            "         [ 1.5412e+00,  7.7669e-01, -7.0716e-01,  8.4218e-01,  9.5230e-01,\n",
            "           3.8645e-01, -1.9716e-01],\n",
            "         [-1.1214e+00, -1.6868e+00, -9.8022e-01, -2.0333e-01, -1.0721e-01,\n",
            "          -2.8917e-01, -2.8329e-01],\n",
            "         [-6.6083e-01,  1.4365e-01,  8.9321e-01,  2.8468e-01, -6.2773e-01,\n",
            "          -2.9846e-01, -2.2992e-02],\n",
            "         [-6.4593e-01, -1.4231e-01,  6.2752e-01,  5.4230e-01, -5.2700e-01,\n",
            "          -2.1525e-02, -1.7771e-01],\n",
            "         [ 3.8713e-01, -3.2822e-01, -1.2208e+00, -1.1467e-01,  4.4391e-01,\n",
            "          -1.8816e-01, -4.1137e-01],\n",
            "         [ 1.6285e-01,  1.1739e+00,  1.2988e+00, -1.4164e+00, -7.8836e-01,\n",
            "           2.3993e-01,  6.0362e-01],\n",
            "         [ 8.5413e-01,  9.9047e-01, -8.3250e-01, -4.4232e-01, -1.7408e-01,\n",
            "           3.7041e-01,  8.3970e-02],\n",
            "         [-5.5287e-01,  3.3151e-01,  1.6711e+00,  7.6814e-01, -3.4783e-01,\n",
            "          -1.6685e-01, -4.4047e-02],\n",
            "         [-7.4914e-01, -9.2369e-01,  2.8416e-01,  1.2272e+00,  1.1300e-01,\n",
            "          -1.7786e-01, -3.9465e-01],\n",
            "         [ 2.0536e-02,  6.1811e-01, -1.4246e-02,  2.4094e-01, -9.8855e-02,\n",
            "           3.1046e-01,  6.0419e-02],\n",
            "         [ 2.5457e-01, -3.4568e-01, -1.0053e-01,  4.3335e-01,  2.9212e-01,\n",
            "           2.2105e-01,  2.0540e-01],\n",
            "         [ 3.8213e-01, -1.3772e-02, -1.0433e+00, -4.8821e-01,  3.1787e-01,\n",
            "           4.4165e-01,  3.6309e-01],\n",
            "         [-2.5280e-01, -9.2405e-01, -2.2719e+00, -5.9886e-01,  3.3376e-01,\n",
            "           2.8858e-01,  2.5451e-01],\n",
            "         [ 3.8321e-01, -4.4898e-01, -8.6477e-01, -5.9525e-01,  1.5443e-01,\n",
            "          -1.9926e-02, -2.3243e-01],\n",
            "         [ 6.4347e-02,  6.5314e-01,  2.0896e+00, -6.5964e-01, -4.4761e-01,\n",
            "          -3.2850e-01, -9.4429e-02],\n",
            "         [ 2.3611e-01, -1.4615e-01,  1.1372e+00, -5.8306e-01, -6.9219e-03,\n",
            "          -4.2182e-01, -2.1941e-01],\n",
            "         [ 8.5760e-01,  8.9105e-01, -7.6168e-02,  8.9148e-01,  3.1155e-01,\n",
            "          -1.1923e-02, -1.6073e-01],\n",
            "         [ 1.3665e-01,  5.6764e-01,  1.5776e+00, -1.3796e-01,  1.3853e-02,\n",
            "          -1.5138e-02,  5.9605e-01],\n",
            "         [ 8.0019e-01,  2.0192e-01,  1.1907e-01,  3.0230e-01,  4.1934e-01,\n",
            "          -7.0072e-02, -2.6803e-01],\n",
            "         [ 3.3685e-01, -4.4368e-01, -1.2923e+00,  3.8939e-02,  5.1042e-01,\n",
            "          -3.6355e-01, -1.6443e-01],\n",
            "         [ 5.4173e-02,  9.9637e-01,  1.9184e+00, -9.3387e-01, -3.3146e-01,\n",
            "          -2.7860e-01,  5.5732e-01],\n",
            "         [-2.2267e-02, -1.1571e+00, -1.7982e+00,  1.0104e+00,  3.9038e-01,\n",
            "          -2.6526e-01, -9.9744e-01]]], grad_fn=<SqueezeBackward1>)\n",
            "----------------------------------\n",
            "torch.Size([4, 32, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qIHB-q11UTI",
        "outputId": "31dbbad8-9f32-4663-a8c1-e270ebf37dad"
      },
      "source": [
        "for batch in train_iterator:\n",
        "    print(\"imput:\", batch.text, \"shape:\", batch.label)\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "    for i in batch.text:\n",
        "        print(\"imput:\", [TEXT.vocab.itos[j] for j in i])\n",
        "\n",
        "    em=nn.Embedding(len(TEXT.vocab), 3)(batch.text.cpu())\n",
        "    em=em.permute(0, 2, 1)\n",
        "\n",
        "    c=nn.Conv1d(in_channels=3, out_channels=32, kernel_size=2, padding=1)(em)\n",
        "    p=nn.MaxPool1d(2)(c)\n",
        "    print(\"*3---------------------------------\")\n",
        "\n",
        "    print(p)\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "    print(p.shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imput: tensor([[ 9,  2, 15, 10,  3,  6],\n",
            "        [ 1,  1,  1,  7,  2,  5],\n",
            "        [ 1,  1, 13, 11,  8, 16],\n",
            "        [ 1, 12,  2, 14,  4, 17]]) shape: tensor([2, 1, 0, 0])\n",
            "---------------------------------\n",
            "imput: ['life', 'is', 'such', 'like', '0', 'chanse']\n",
            "imput: ['<pad>', '<pad>', '<pad>', 'engineering', 'is', 'borring']\n",
            "imput: ['<pad>', '<pad>', 'seal', 'likes', 'fish', 'too']\n",
            "imput: ['<pad>', 'nature', 'is', 'see', 'and', 'tree']\n",
            "*3---------------------------------\n",
            "tensor([[[ 0.7630,  1.0241,  0.1259],\n",
            "         [-0.2652,  0.2799, -0.6315],\n",
            "         [-0.8898,  0.0705,  0.3301],\n",
            "         [-0.4626, -0.6172,  0.7400],\n",
            "         [ 0.3662,  0.4131,  0.3637],\n",
            "         [ 1.0642,  0.9323, -0.3762],\n",
            "         [ 0.2799,  0.5064,  0.5313],\n",
            "         [ 0.6897,  0.1545,  0.1460],\n",
            "         [ 1.0685,  0.5423, -0.1613],\n",
            "         [ 0.7099,  0.3879, -0.1065],\n",
            "         [ 0.3349, -0.0366,  0.3504],\n",
            "         [ 0.0099, -0.2381,  0.7677],\n",
            "         [-0.7351, -0.1716,  0.1261],\n",
            "         [ 0.3708,  0.9690, -0.2579],\n",
            "         [ 1.2057,  0.8174, -1.0683],\n",
            "         [-0.1357,  0.3203,  0.9836],\n",
            "         [ 0.4919,  0.5303, -0.9874],\n",
            "         [ 0.7681,  0.3377, -0.4943],\n",
            "         [ 1.0955,  1.0904, -0.0803],\n",
            "         [ 0.1557,  0.3245, -0.0731],\n",
            "         [-0.5579, -0.4552,  0.4557],\n",
            "         [ 1.4721,  0.8176, -0.3979],\n",
            "         [ 0.4990,  0.1475,  0.5535],\n",
            "         [ 0.0383,  0.5802, -0.5064],\n",
            "         [ 0.2114,  0.5681,  0.6543],\n",
            "         [ 0.4262,  0.4067, -0.1117],\n",
            "         [ 0.6829,  0.1632,  0.8728],\n",
            "         [ 0.4271, -0.0893,  0.6808],\n",
            "         [ 0.5134,  0.9000,  0.7638],\n",
            "         [ 0.8846,  0.2650, -0.0929],\n",
            "         [ 0.8634,  0.4602,  1.3967],\n",
            "         [ 0.0079,  0.2700, -0.0619]],\n",
            "\n",
            "        [[ 0.5878,  0.5878,  0.3404],\n",
            "         [-0.2212, -0.3683,  0.4550],\n",
            "         [-0.7767, -0.1376, -0.3547],\n",
            "         [-0.2452,  0.0605, -0.2626],\n",
            "         [ 0.1427,  0.0711,  0.9045],\n",
            "         [ 1.1683,  1.1683,  0.6496],\n",
            "         [ 0.3343,  0.1010,  0.3316],\n",
            "         [ 0.4850,  0.4383,  0.9922],\n",
            "         [ 0.4826,  0.1815,  0.9645],\n",
            "         [ 0.4085,  0.1812,  0.6545],\n",
            "         [-0.1399, -0.0699,  0.9317],\n",
            "         [ 0.0254, -0.0902,  0.0974],\n",
            "         [-0.7857, -0.1694, -0.3082],\n",
            "         [ 0.2990,  0.1675,  0.9209],\n",
            "         [ 1.2329,  1.2329,  0.9426],\n",
            "         [-0.0197,  0.6781,  0.1931],\n",
            "         [ 0.3834,  0.3834,  0.2707],\n",
            "         [ 0.5926,  0.5926,  0.2525],\n",
            "         [ 0.4331,  0.4331,  0.5941],\n",
            "         [-0.0330,  0.5310, -0.5228],\n",
            "         [-0.2139, -0.2009,  0.5554],\n",
            "         [ 0.8221,  0.8221,  0.0964],\n",
            "         [-0.2419,  0.4483, -0.4019],\n",
            "         [ 0.0164, -0.1119,  0.1868],\n",
            "         [ 0.1460,  0.4665,  1.1266],\n",
            "         [-0.0114, -0.0114,  0.2134],\n",
            "         [ 0.3986,  0.1400,  1.1365],\n",
            "         [ 0.3538,  0.2265,  0.6371],\n",
            "         [ 0.5440,  0.3867,  1.3012],\n",
            "         [ 0.7270,  0.7270,  0.7306],\n",
            "         [ 0.0845,  1.1364,  0.4961],\n",
            "         [-0.1049,  0.1979,  0.1369]],\n",
            "\n",
            "        [[ 0.5878,  0.2804,  0.5802],\n",
            "         [-0.2212, -0.3884,  0.1929],\n",
            "         [-0.7767, -0.4133,  0.0436],\n",
            "         [-0.2452,  0.1470, -0.5041],\n",
            "         [ 0.1427,  0.5997,  0.7140],\n",
            "         [ 1.1683,  0.9877,  0.4835],\n",
            "         [ 0.3343, -0.0110,  0.3693],\n",
            "         [ 0.4850,  0.9240,  0.3553],\n",
            "         [ 0.4826,  0.0432,  0.2423],\n",
            "         [ 0.4085,  0.0488,  0.2852],\n",
            "         [-0.1399,  0.8888,  0.3924],\n",
            "         [ 0.0254,  0.3026, -0.2439],\n",
            "         [-0.7857, -0.1568, -0.1598],\n",
            "         [ 0.2990,  0.2261,  0.0405],\n",
            "         [ 1.2329,  0.9386,  0.4255],\n",
            "         [-0.0197,  0.6584,  0.1474],\n",
            "         [ 0.3834,  0.1349, -0.0950],\n",
            "         [ 0.5926,  0.4835,  0.1268],\n",
            "         [ 0.4331, -0.1378,  0.8999],\n",
            "         [-0.0330,  0.1886,  0.0093],\n",
            "         [-0.2139,  0.6849, -0.1299],\n",
            "         [ 0.8221,  0.6943,  0.3352],\n",
            "         [-0.2419, -0.0889, -0.0572],\n",
            "         [ 0.0164, -0.3483, -0.0460],\n",
            "         [ 0.1460,  1.2417,  0.6517],\n",
            "         [-0.0114,  0.0061, -0.1662],\n",
            "         [ 0.3986,  0.7521, -0.1148],\n",
            "         [ 0.3538,  0.6998,  0.1194],\n",
            "         [ 0.5440,  0.8712,  0.1781],\n",
            "         [ 0.7270,  0.8652,  0.3444],\n",
            "         [ 0.0845,  1.3129,  0.6922],\n",
            "         [-0.1049,  0.3647,  0.2180]],\n",
            "\n",
            "        [[ 0.5242,  0.7529, -0.4816],\n",
            "         [-0.0888, -0.0831, -0.9108],\n",
            "         [-0.6813,  0.1191,  0.7955],\n",
            "         [-0.2452, -0.1656,  1.2038],\n",
            "         [ 0.6134,  0.3135,  1.1876],\n",
            "         [ 0.8623,  0.5105, -0.9595],\n",
            "         [ 0.3343,  0.5176,  0.5208],\n",
            "         [ 0.4850,  0.0543,  0.2540],\n",
            "         [ 0.4826,  0.3232, -0.2196],\n",
            "         [ 0.4085,  0.0359, -0.3959],\n",
            "         [ 0.3141,  0.0040,  1.0155],\n",
            "         [ 0.0254, -0.2551,  0.3563],\n",
            "         [-0.6210, -0.1950,  0.6175],\n",
            "         [ 0.2990,  0.3424, -0.7704],\n",
            "         [ 1.3073,  0.6264, -0.8306],\n",
            "         [-0.1098,  0.3305,  0.9764],\n",
            "         [ 0.2309,  0.2905, -1.1463],\n",
            "         [ 0.5062,  0.3312, -0.3860],\n",
            "         [ 0.8216,  1.3102, -0.3725],\n",
            "         [-0.2707, -0.0569, -0.6972],\n",
            "         [-0.3549, -1.0311, -0.2131],\n",
            "         [ 0.7009,  0.8184, -0.8390],\n",
            "         [-0.3775,  0.3226,  0.3462],\n",
            "         [ 0.0164,  0.2552, -0.9101],\n",
            "         [ 0.5226,  0.0614,  1.5251],\n",
            "         [-0.0731,  0.4667, -0.2007],\n",
            "         [ 0.3986,  0.6261,  1.0730],\n",
            "         [ 0.3538, -0.2919,  0.6028],\n",
            "         [ 0.5440,  0.8767,  0.5412],\n",
            "         [ 0.8373,  0.0864,  0.2409],\n",
            "         [ 0.0299,  0.2802,  0.9159],\n",
            "         [-0.0942, -0.2668, -0.3879]]], grad_fn=<SqueezeBackward1>)\n",
            "---------------------------------\n",
            "torch.Size([4, 32, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Dsg7HX1u4d",
        "outputId": "abe9fbb9-c257-4eb0-fd48-3806b5bf48ee"
      },
      "source": [
        "for batch in train_iterator:\n",
        "    print(\"imput:\", batch.text, \"shape:\", batch.label)\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "    for i in batch.text:\n",
        "        print(\"imput:\", [TEXT.vocab.itos[j] for j in i])\n",
        "\n",
        "    em=nn.Embedding(len(TEXT.vocab), 3)(batch.text.cpu())\n",
        "\n",
        "    em=em.permute(0, 2, 1)\n",
        "\n",
        "    c=nn.Conv1d(in_channels=3, out_channels=32, kernel_size=2, padding=1)(em)\n",
        "\n",
        "    p=nn.MaxPool1d(2)(c)\n",
        "    print(\"*4---------------------------------\")\n",
        "\n",
        "    o = p.permute(0, 2, 1)\n",
        "    print(o)\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "    print(o.shape)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imput: tensor([[ 1,  1,  1,  7,  2,  5],\n",
            "        [ 9,  2, 15, 10,  3,  6],\n",
            "        [ 1,  1, 13, 11,  8, 16],\n",
            "        [ 1, 12,  2, 14,  4, 17]]) shape: tensor([1, 2, 0, 0])\n",
            "---------------------------------\n",
            "imput: ['<pad>', '<pad>', '<pad>', 'engineering', 'is', 'borring']\n",
            "imput: ['life', 'is', 'such', 'like', '0', 'chanse']\n",
            "imput: ['<pad>', '<pad>', 'seal', 'likes', 'fish', 'too']\n",
            "imput: ['<pad>', 'nature', 'is', 'see', 'and', 'tree']\n",
            "*4---------------------------------\n",
            "tensor([[[ 9.2426e-01,  4.9562e-01,  2.8078e-01, -3.7427e-01, -2.0895e-01,\n",
            "           5.7905e-01,  2.7768e-01, -3.8824e-01,  1.8917e-01,  1.3327e-01,\n",
            "           9.7212e-01, -9.8028e-02, -3.4746e-01,  5.9648e-02,  4.2253e-01,\n",
            "           4.6274e-02,  3.9327e-01,  6.5917e-01,  3.4731e-01,  2.7528e-01,\n",
            "           4.3690e-01, -8.8091e-02, -5.2617e-02,  1.9718e-01,  1.7459e-01,\n",
            "          -5.4596e-01,  3.7665e-01,  1.6080e-01, -3.7634e-01, -1.5558e-01,\n",
            "           4.9415e-01,  2.2199e-01],\n",
            "         [ 9.2426e-01,  4.9562e-01, -9.9356e-02, -7.1567e-01, -2.1253e-01,\n",
            "           7.0909e-01,  2.7768e-01, -9.3150e-01,  1.8917e-01, -6.7871e-02,\n",
            "           9.9265e-01,  5.9749e-02, -1.0388e-01,  9.8939e-02,  1.3492e-01,\n",
            "           1.3751e-01,  2.8288e-01,  9.5677e-01,  3.4731e-01, -5.4788e-02,\n",
            "           4.3690e-01,  5.2451e-01,  4.4827e-01,  1.9718e-01, -2.8175e-01,\n",
            "          -5.5428e-01,  9.7118e-01,  7.6523e-01, -3.1551e-01, -5.4876e-01,\n",
            "           7.2586e-01,  2.2199e-01],\n",
            "         [ 5.0962e-01,  4.5946e-01,  4.6381e-01,  1.5927e-01, -7.3938e-02,\n",
            "           2.2831e-01,  2.5031e-01, -1.7620e-01,  7.4372e-01,  1.5999e-01,\n",
            "           1.0896e+00,  3.8778e-01, -9.5597e-01, -1.5942e-01,  7.3989e-01,\n",
            "          -2.6113e-02,  3.1199e-01,  6.6349e-01, -7.3555e-02,  4.0061e-01,\n",
            "           1.6101e-01,  1.3567e-01,  1.1937e-02, -7.1897e-02,  2.5258e-01,\n",
            "           1.3337e-02,  2.0712e-01,  7.5827e-01, -1.3919e-02, -5.4512e-01,\n",
            "           4.3432e-01,  1.0670e+00]],\n",
            "\n",
            "        [[ 3.7013e-01,  1.7831e-01,  4.3835e-01, -3.5587e-01, -3.9328e-01,\n",
            "           4.6184e-01,  3.6741e-01, -4.3152e-01,  6.1097e-01, -1.4146e-01,\n",
            "           9.0786e-01,  4.6280e-01, -7.6311e-01, -2.5959e-01,  6.2258e-01,\n",
            "          -1.0509e-02,  6.0605e-02,  8.9520e-01,  5.4690e-02,  2.5249e-01,\n",
            "          -2.0579e-02,  3.7511e-01,  1.9514e-01, -3.0989e-02, -1.4539e-01,\n",
            "           2.0571e-01,  6.0888e-01,  6.1959e-01,  9.8890e-02, -4.4188e-01,\n",
            "           6.9201e-01,  7.7417e-01],\n",
            "         [ 5.7062e-01,  8.4844e-01,  1.5497e-01, -2.0372e-01, -3.7785e-01,\n",
            "           5.0319e-01, -3.4755e-01, -4.0874e-01,  5.1037e-01,  8.1225e-02,\n",
            "           1.0909e+00,  2.8020e-01, -2.9860e-01,  2.1253e-01,  3.8087e-01,\n",
            "           5.8475e-01, -4.3740e-02,  1.1192e+00, -3.1033e-01, -6.3187e-02,\n",
            "           2.1983e-01,  1.0774e+00,  1.7369e-01, -7.4593e-01,  4.2285e-01,\n",
            "          -6.8650e-01,  9.7283e-01,  3.8668e-01,  1.1419e-01, -6.3226e-02,\n",
            "           7.0175e-01,  4.1666e-01],\n",
            "         [ 1.1049e-01,  5.7781e-03,  4.2296e-01,  2.7229e-01, -8.9960e-02,\n",
            "           2.5115e-01,  5.6214e-01, -5.6236e-02,  6.9823e-01,  1.4704e-01,\n",
            "           6.5147e-01,  4.0921e-01, -2.9440e-01, -1.3151e-01,  6.5612e-01,\n",
            "          -8.1416e-02,  2.6356e-01,  3.9914e-01,  1.6631e-01,  4.1370e-01,\n",
            "          -2.0490e-01,  3.8094e-01,  1.4530e-01,  4.1119e-01,  2.9347e-01,\n",
            "           1.1372e-01,  1.1299e-01,  8.2149e-01,  1.6989e-01, -1.7936e-01,\n",
            "           5.6850e-01,  9.6272e-01]],\n",
            "\n",
            "        [[ 9.2426e-01,  4.9562e-01,  2.8078e-01, -3.7427e-01, -2.0895e-01,\n",
            "           5.7905e-01,  2.7768e-01, -3.8824e-01,  1.8917e-01,  1.3327e-01,\n",
            "           9.7212e-01, -9.8028e-02, -3.4746e-01,  5.9648e-02,  4.2253e-01,\n",
            "           4.6274e-02,  3.9327e-01,  6.5917e-01,  3.4731e-01,  2.7528e-01,\n",
            "           4.3690e-01, -8.8091e-02, -5.2617e-02,  1.9718e-01,  1.7459e-01,\n",
            "          -5.4596e-01,  3.7665e-01,  1.6080e-01, -3.7634e-01, -1.5558e-01,\n",
            "           4.9415e-01,  2.2199e-01],\n",
            "         [-2.0313e-02, -1.6597e-01,  8.4484e-01, -3.4768e-01, -3.9500e-01,\n",
            "           5.0526e-01,  5.9641e-01,  4.1589e-01,  6.9011e-01,  6.4862e-02,\n",
            "           3.4791e-01,  3.8726e-01,  7.8878e-01,  2.5913e-01,  8.1219e-01,\n",
            "          -4.2645e-02,  4.0101e-01,  6.0790e-01,  4.0882e-01,  6.8096e-01,\n",
            "           4.7537e-02,  6.8550e-01,  2.7116e-01,  5.7033e-01,  2.1931e-01,\n",
            "          -2.1252e-01,  1.4059e-01,  9.2519e-01,  5.9957e-01,  3.0358e-01,\n",
            "           6.0195e-01,  5.5846e-01],\n",
            "         [-2.7636e-01, -3.3895e-01, -3.6278e-01,  8.3596e-02, -6.0472e-01,\n",
            "           3.3818e-01,  2.3888e-01,  1.1511e+00,  5.4027e-01,  2.0323e-01,\n",
            "           3.0855e-01,  4.8313e-01, -1.0124e-02, -3.0263e-02,  6.6062e-02,\n",
            "          -3.4219e-02, -4.9793e-01,  4.5205e-01, -1.5590e-01, -2.6890e-01,\n",
            "          -1.3963e-01,  8.2925e-01,  2.8815e-01, -9.6491e-02,  2.8552e-01,\n",
            "          -3.1301e-02, -1.7566e-01,  9.6360e-01,  7.3953e-01,  6.5891e-01,\n",
            "           5.7582e-01,  3.6609e-01]],\n",
            "\n",
            "        [[ 8.0115e-01,  1.3290e-01,  2.8078e-01, -2.9483e-01, -5.1692e-02,\n",
            "           4.6920e-01,  9.3635e-01, -2.0894e-01,  4.2400e-01,  5.9730e-01,\n",
            "           7.8995e-01, -9.2378e-02, -1.1147e-01,  1.4652e-01,  4.2253e-01,\n",
            "           4.6274e-02,  4.7474e-01,  6.0444e-01,  8.2134e-01,  2.7528e-01,\n",
            "           3.8269e-01, -1.1903e-01, -2.4469e-01,  7.7548e-01,  1.7459e-01,\n",
            "           1.3067e-01,  2.1416e-01, -1.6823e-01, -2.7512e-02, -1.5558e-01,\n",
            "           2.3173e-01,  3.0532e-01],\n",
            "         [ 2.4295e-01, -4.5300e-01,  3.8313e-01,  2.9586e-01, -1.3210e-03,\n",
            "           4.0300e-01,  6.8696e-01, -1.3946e-03,  6.2154e-04,  5.4987e-02,\n",
            "           2.4307e-01,  2.5218e-01,  2.0790e-01,  2.8391e-01,  6.0043e-01,\n",
            "           9.2861e-02,  2.4605e-01,  6.0411e-02,  8.1306e-02,  4.0568e-01,\n",
            "           4.9755e-02,  6.6514e-01,  5.4459e-01,  1.0073e+00,  3.5113e-01,\n",
            "           1.3498e-01,  3.6474e-01,  5.9664e-01,  4.7042e-01,  7.1480e-02,\n",
            "           8.6203e-01,  9.1828e-01],\n",
            "         [ 7.6140e-02,  3.3807e-02,  2.4363e-01, -4.8464e-01, -3.8661e-01,\n",
            "           5.6594e-01, -2.3887e-02,  1.1724e-01,  2.4426e-01, -5.0158e-02,\n",
            "           5.6642e-01,  1.4837e-01,  5.6526e-02, -6.9546e-02,  4.9674e-01,\n",
            "           3.1605e-02,  1.9540e-02,  6.5096e-01, -4.1956e-01,  1.0272e-01,\n",
            "          -2.8954e-01,  4.6247e-01,  3.8661e-01,  4.7674e-02,  3.4527e-02,\n",
            "          -5.4950e-01,  2.7066e-01,  6.4290e-01, -9.8691e-02,  1.1874e-01,\n",
            "           8.0729e-02,  4.8570e-01]]], grad_fn=<PermuteBackward>)\n",
            "---------------------------------\n",
            "torch.Size([4, 3, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkxRHGOZ2ODs",
        "outputId": "811cd119-c296-4193-9b2e-92b10f914fce"
      },
      "source": [
        " for batch in train_iterator:\n",
        "    print(\"imput:\", batch.text, \"shape:\", batch.label)\n",
        "    print(\"---------------------------------\")\n",
        "    for i in batch.text:\n",
        "        print(\"imput:\", [TEXT.vocab.itos[j] for j in i])\n",
        "\n",
        "    em=nn.Embedding(len(TEXT.vocab), 3)(batch.text.cpu())\n",
        "    em=em.permute(0, 2, 1)\n",
        "    c=nn.Conv1d(in_channels=3, out_channels=32, kernel_size=2, padding=1)(em)\n",
        "    p=nn.MaxPool1d(2)(c)\n",
        "    o = p.permute(0, 2, 1)\n",
        "    print(o.shape)\n",
        "    # max pool\n",
        "    print(\"*5---------------------------------\")\n",
        "    o, _ = torch.max(o, 1)\n",
        "    print(o)\n",
        "    print(\"---------------------------------\")\n",
        "    print(o.shape)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imput: tensor([[ 1,  1, 13, 11,  8, 16],\n",
            "        [ 9,  2, 15, 10,  3,  6],\n",
            "        [ 1,  1,  1,  7,  2,  5],\n",
            "        [ 1, 12,  2, 14,  4, 17]]) shape: tensor([0, 2, 1, 0])\n",
            "---------------------------------\n",
            "imput: ['<pad>', '<pad>', 'seal', 'likes', 'fish', 'too']\n",
            "imput: ['life', 'is', 'such', 'like', '0', 'chanse']\n",
            "imput: ['<pad>', '<pad>', '<pad>', 'engineering', 'is', 'borring']\n",
            "imput: ['<pad>', 'nature', 'is', 'see', 'and', 'tree']\n",
            "torch.Size([4, 3, 32])\n",
            "*5---------------------------------\n",
            "tensor([[ 6.7171e-01,  9.3287e-02,  4.4010e-01,  3.5686e-01,  1.2296e+00,\n",
            "          6.3973e-01,  2.7642e-01,  6.4191e-01,  1.0323e+00,  1.3804e+00,\n",
            "          6.1779e-01,  4.3577e-01,  1.0779e+00,  4.7280e-01,  6.0774e-01,\n",
            "          3.3416e-01,  2.9088e-01,  2.5850e-01,  1.0748e+00,  3.3299e-01,\n",
            "          7.9122e-01,  5.6351e-01,  7.4564e-01,  8.9999e-02,  1.2044e+00,\n",
            "          1.6545e-01,  5.7618e-01,  4.4837e-01,  6.8160e-02,  6.3554e-01,\n",
            "          2.1701e-01,  5.8270e-01],\n",
            "        [ 6.5912e-01,  9.6199e-01, -5.0945e-03,  2.5310e-01,  9.4447e-01,\n",
            "          9.1808e-01,  1.2993e+00,  6.4067e-01,  9.5785e-01,  7.1676e-01,\n",
            "          5.0709e-01,  4.4620e-01,  1.8027e+00,  6.9673e-01,  7.3934e-01,\n",
            "          4.0482e-01,  6.9438e-01,  3.3076e-01,  8.6449e-01,  4.6137e-01,\n",
            "          3.5692e-01,  1.0295e+00,  7.0421e-01,  3.7767e-01,  8.3055e-01,\n",
            "          3.3236e-01,  4.5728e-01,  1.2864e+00, -9.3117e-04,  5.9557e-01,\n",
            "          3.3089e-01,  6.1749e-01],\n",
            "        [ 5.6365e-01,  1.8452e-01,  1.7905e-01,  7.7314e-02,  1.2296e+00,\n",
            "          5.8043e-01,  3.1982e-02,  2.8380e-02,  1.1037e+00,  1.0480e+00,\n",
            "          8.5184e-02,  4.5468e-01,  2.7429e-01,  2.4089e-01,  6.9891e-01,\n",
            "          4.5887e-01,  6.9196e-01, -7.2313e-03,  3.9567e-01,  1.6808e-01,\n",
            "          7.9122e-01,  5.3783e-01,  7.4564e-01, -1.3252e-01,  5.3459e-01,\n",
            "         -3.2522e-01,  5.4358e-01,  1.3238e+00,  1.9636e-01,  6.8481e-01,\n",
            "          4.5455e-01,  4.3603e-01],\n",
            "        [ 5.0329e-01,  3.6499e-01,  4.5984e-01,  6.6598e-01,  1.0359e+00,\n",
            "          9.7853e-01,  7.8348e-02,  2.8371e-01,  1.9455e+00,  1.7414e+00,\n",
            "          5.6331e-01,  8.1248e-01,  1.2273e+00,  6.1543e-01,  7.1147e-01,\n",
            "          9.0545e-02,  6.3158e-02,  1.9710e-02,  5.3468e-01,  4.2896e-01,\n",
            "          7.0170e-01,  2.7105e-01,  6.9784e-01,  5.3456e-01,  9.0414e-01,\n",
            "          1.0982e-01,  3.6945e-01,  4.2470e-01,  5.5383e-02,  8.1171e-01,\n",
            "          4.6287e-01,  3.9005e-01]], grad_fn=<MaxBackward0>)\n",
            "---------------------------------\n",
            "torch.Size([4, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-REOpUG2tIE",
        "outputId": "15482d9f-f248-4b1d-c027-999c0948ed83"
      },
      "source": [
        "for batch in train_iterator:\n",
        "    print(\"imput:\", batch.text, \"shape:\", batch.label)\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "    for i in batch.text:\n",
        "        print(\"imput:\", [TEXT.vocab.itos[j] for j in i])\n",
        "\n",
        "    em=nn.Embedding(len(TEXT.vocab), 3)(batch.text.cpu())\n",
        "\n",
        "    em=em.permute(0, 2, 1)\n",
        "\n",
        "    c=nn.Conv1d(in_channels=3, out_channels=32, kernel_size=2, padding=1)(em)\n",
        "\n",
        "    p=nn.MaxPool1d(2)(c)\n",
        "\n",
        "    o = p.permute(0, 2, 1)\n",
        "\n",
        "    # max pool\n",
        "    o, _ = torch.max(o, 1)\n",
        "\n",
        "    l=nn.Linear(32, 3)(o)\n",
        "    print(\"*6---------------------------------\")\n",
        "\n",
        "    print(l)\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "    print(l.shape)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imput: tensor([[ 9,  2, 15, 10,  3,  6],\n",
            "        [ 1,  1, 13, 11,  8, 16],\n",
            "        [ 1, 12,  2, 14,  4, 17],\n",
            "        [ 1,  1,  1,  7,  2,  5]]) shape: tensor([2, 0, 0, 1])\n",
            "---------------------------------\n",
            "imput: ['life', 'is', 'such', 'like', '0', 'chanse']\n",
            "imput: ['<pad>', '<pad>', 'seal', 'likes', 'fish', 'too']\n",
            "imput: ['<pad>', 'nature', 'is', 'see', 'and', 'tree']\n",
            "imput: ['<pad>', '<pad>', '<pad>', 'engineering', 'is', 'borring']\n",
            "*6---------------------------------\n",
            "tensor([[-0.6624, -0.2285,  1.8863],\n",
            "        [-0.7063,  0.0516,  1.3766],\n",
            "        [-0.2594,  0.4202,  1.3718],\n",
            "        [-0.6481,  0.1403,  1.2128]], grad_fn=<AddmmBackward>)\n",
            "---------------------------------\n",
            "torch.Size([4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICd7kK246O6d"
      },
      "source": [
        "This will be followed by\n",
        "nn.CrossEntropyLoss() which combines LogSoftmax and NLLLoss. in other words it will output 4x3 matrix"
      ]
    }
  ]
}